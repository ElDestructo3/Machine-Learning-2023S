{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing models\n",
    "\n",
    "import numpy as np \n",
    "from numpy import linalg \n",
    "from cvxopt import solvers\n",
    "import cvxopt.solvers                  # cvxopt for solving the dual optimization problem \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MoIP</th>\n",
       "      <th>SDoIP</th>\n",
       "      <th>EkIP</th>\n",
       "      <th>SoIP</th>\n",
       "      <th>MoDM-SNR</th>\n",
       "      <th>SDDM-SNR</th>\n",
       "      <th>EkDM-SNR</th>\n",
       "      <th>SoDM-SNR</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MoIP      SDoIP      EkIP      SoIP  MoDM-SNR   SDDM-SNR   EkDM-SNR  \\\n",
       "0  140.562500  55.683782 -0.234571 -0.699648  3.199833  19.110426   7.975532   \n",
       "1  102.507812  58.882430  0.465318 -0.515088  1.677258  14.860146  10.576487   \n",
       "2  103.015625  39.341649  0.323328  1.051164  3.121237  21.744669   7.735822   \n",
       "3  136.750000  57.178449 -0.068415 -0.636238  3.642977  20.959280   6.896499   \n",
       "4   88.726562  40.672225  0.600866  1.123492  1.178930  11.468720  14.269573   \n",
       "\n",
       "     SoDM-SNR  Class  \n",
       "0   74.242225      0  \n",
       "1  127.393580      0  \n",
       "2   63.171909      0  \n",
       "3   53.593661      0  \n",
       "4  252.567306      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pulsar_star_dataset.csv')\n",
    "df.head()                                                           # reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']                                                                                     # splitting the dataset into features and labels\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()                                                                                    # converting the dataset into numpy array for ease of use\n",
    "y[y == 0] = -1                                                                                      # converting the labels to -1 and 1, as per the SVM problem formulation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)           # splitting the dataset into train and test set\n",
    "mean_train = X_train.mean()                                                                         # standardizing the dataset\n",
    "std_train = X_train.std()\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "X_test = (X_test - mean_train) / std_train                                                          # standardizing the test set using the mean and standard deviation of the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "\n",
    "    def linear_kernel(self, x1, x2):                                                            # defining the kernel functions, using numpy vectorisation to speed up the process\n",
    "        return np.dot(x1, x2) * 1.                                                              # multiplying here and elsewhere by 1. to convert to float required by cvxopt\n",
    "\n",
    "    def quadratic_kernel(self, x1, x2):\n",
    "        return ((1 + np.dot(x1, x2))*1.) ** 2                                \n",
    "\n",
    "    def gaussian_kernel(self, x1, x2):   \n",
    "        x2 = x2.T                                           \n",
    "        X_norm = np.sum(x1 ** 2, axis = -1)\n",
    "        Y_norm = np.sum(x2 ** 2, axis = -1)\n",
    "        return np.exp(-self.gamma * (X_norm[:,None] + Y_norm[None,:] - 2 * np.dot(x1, x2.T)))   # expanding || x- y || ^2 = || x || ^2 + || y || ^2 - 2 * x.T * y\n",
    "\n",
    "    def __init__(self, kernel_str='linear', C=1.0, gamma=0.1):                                 # initializing the SVM class\n",
    "        if kernel_str == 'linear':\n",
    "            self.kernel = SVM.linear_kernel\n",
    "        elif kernel_str == 'quadratic':\n",
    "            self.kernel = SVM.quadratic_kernel\n",
    "        elif kernel_str == 'gaussian':\n",
    "            self.kernel = SVM.gaussian_kernel\n",
    "        else:\n",
    "            self.kernel = SVM.linear_kernel\n",
    "            print('Invalid kernel string, defaulting to linear.')\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.kernel_str = kernel_str\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        kernel_matrix = np.zeros((num_samples, num_samples))                                                    # creating the kernel matrix\n",
    "        kernel_matrix = self.kernel(self, X, X.T)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y,y) * kernel_matrix)                                                    # creating the matrices for the dual optimization problem, derivation explained in report\n",
    "        q = cvxopt.matrix(np.ones(num_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,num_samples)) * 1.\n",
    "        b = cvxopt.matrix(0) * 1.                                                                                        \n",
    "        G_upper = np.diag(np.ones(num_samples) * -1)\n",
    "        G_lower = np.identity(num_samples)\n",
    "        G = cvxopt.matrix(np.vstack((G_upper, G_lower)))\n",
    "        h_upper = np.zeros(num_samples)\n",
    "        h_lower = np.ones(num_samples) * self.C\n",
    "        h = cvxopt.matrix(np.hstack((h_upper, h_lower)))\n",
    "\n",
    "        solvers.options['show_progress'] = False                                                            # turning off the progress bar of cvxopt\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)                                                      # running the qp solver of cvxopt to solve the dual optimization problem\n",
    "        a = np.ravel(solution['x'])                                                                         # get the lagrange multipliers from the solution\n",
    "        support_vectors = a > 1e-4                                                                          # get the support vectors which have non-zero lagrange multipliers\n",
    "        ind = np.arange(len(a))[support_vectors]                                                            # get the indices of the support vectors for the kernel matrix\n",
    "        self.a = a[support_vectors]                                                                         # storing the data of the solution in the svm object\n",
    "        self.support_vectors = X[support_vectors]\n",
    "        self.y_support_vectors = y[support_vectors]\n",
    "        print(\"%d support vectors out of %d points\" % (len(self.a), num_samples))\n",
    "\n",
    "        self.b = 0                                                                                          # deriving the bias value by enforcing the constraint for b in the svm optimization problem\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.y_support_vectors[n]\n",
    "            self.b -= np.sum(self.a * self.y_support_vectors * kernel_matrix[ind[n],support_vectors])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        if self.kernel_str == 'linear':                                                                     # deriving the weights for the linear kernel\n",
    "            self.w = np.zeros(num_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.y_support_vectors[n] * self.support_vectors[n]\n",
    "        else:\n",
    "            self.w = None                                                                                   # if the kernel is not linear, then the weights are not defined\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.kernel_str == 'linear':                                                                     # if linear, then the prediction is given by the linear combination of the support vectors\n",
    "            return np.sign(np.dot(X, self.w) + self.b)\n",
    "        else:\n",
    "            y_predict = np.sum(self.a * self.y_support_vectors * self.kernel(self, X, self.support_vectors.T), axis=1)  # if not linear, then the prediction is given by the kernel modification to the standard linear version\n",
    "            y_predict = np.sign(y_predict + self.b)                                                         \n",
    "            return y_predict                                                                                # returning the sign of the prediction (positive meaning +1, negative meaning -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that running on the full dataset is very slow (3-4 hours), so uncomment the code below and run this cell if you wish to check the results more quickly or apply grid search, comment it out again before running the full dataset\n",
    "X_train = X_train[:800]\n",
    "y_train = y_train[:800]\n",
    "X_test = X_test[:200]\n",
    "y_test = y_test[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 support vectors out of 800 points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linear = SVM('linear', 1.0)                                                                             \n",
    "clf_linear.fit(X_train, y_train)\n",
    "y_pred_linear = clf_linear.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 support vectors out of 800 points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.965"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_quadratic = SVM('quadratic', 1.0)\n",
    "clf_quadratic.fit(X_train, y_train)\n",
    "y_pred_quadratic = clf_quadratic.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 support vectors out of 800 points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gaussian = SVM('gaussian', 1.0, 0.1)\n",
    "clf_gaussian.fit(X_train, y_train)\n",
    "y_pred_gaussian = clf_gaussian.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_gaussian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,   3],\n",
       "       [  3,  22]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,   3],\n",
       "       [  4,  21]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[173,   2],\n",
       "       [  7,  18]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_clf_linear = svm.SVC(kernel='linear', C=1.0)\n",
    "sk_clf_linear.fit(X_train, y_train)\n",
    "sk_y_pred_linear = sk_clf_linear.predict(X_test)\n",
    "accuracy_score(y_test, sk_y_pred_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_clf_quadratic = svm.SVC(kernel='poly', degree=2, C=1.0)\n",
    "sk_clf_quadratic.fit(X_train, y_train)\n",
    "sk_y_pred_quadratic = sk_clf_quadratic.predict(X_test)\n",
    "accuracy_score(y_test, sk_y_pred_quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_clf_gaussian = svm.SVC(kernel='rbf', C=1.0, gamma=0.1)\n",
    "sk_clf_gaussian.fit(X_train, y_train)\n",
    "sk_y_pred_gaussian = sk_clf_gaussian.predict(X_test)\n",
    "accuracy_score(y_test, sk_y_pred_gaussian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
